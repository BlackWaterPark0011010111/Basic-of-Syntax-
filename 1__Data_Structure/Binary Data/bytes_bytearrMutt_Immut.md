Сам пк работает с электрическими сигналами.ток либо есть либо нет. 0 ли 1,если переводить в математический язык,так вот 0 и 1 называется битом,но одного бита слишком мало чтобы чтото выразить,поэтому
поэтому биты собираются в кучу из 8-ми штук,которая называется байтом.То есть байт это клетка,которая собирает в себе  8 битов. и каждый бит,он как лампочка,он может быть либо включен либо выключен, то есть либо 0 либо 1.
электричество → 0/1 → бит → байт → кодировка → bytes → bytearray → encode/decode → сеть

и комбинация подобного означает то,что мы можем закодировать что угодно-- и это кодировка.
Соглашение ASCII,таблица соответствия.

Когда мы работаем со строкой например,то мы  всегда работаем с абстракцией,с самой идеей текста. 
и сами байты и биты мы не видим,но внутри памяти это чтобы мы не задавали,эта строка будет выглядеть только через набор этих битов которые содержат эти байты внутри себя.и если мы хотим или нам нужно работать с этими самыми байтами,с этой голой последовательностью байтов,нужно использовать особенные типы данных как bytes и bytearray.
Сам тип bytes, он понятно что не изменяемый,то есть это неизменяемая последовательность байтов.
создать объект bytes можно например из последовательности,то есть мы создаем сами байтовый обьект из чисел,которые отображают соответствие латинским буквам в ASCII кодировке H E L L O, и он будет показывать их нам в читаемой форме.:
b=bytes([72,101,108,108,111])
print(b)---->будет 'Hello'
Это просто представление для нашего собственного удобства,но внутри будут лежать все те же числа.
И изменить их мы никак не сможем,в плане как например заменить  первый объект на другой b[0]=4. Bytes - неизменяем как строка или кортеж,и это делает его безопасным для использования в качестве ключа. Байты всплывают когда мы читаем данные из файла в режиме 'rb' или из сети через сокеты,из сериализованных объектов,то есть это самые сырые и неинтерпретированные данные. 
А bytearray уже как раз изменяемая последовательность байтов,это уже будет как список,но только для чисел от 0 и до 255(атомарный уровень), 2 в 8cтепени минус 1. То есть мы в нем можем,менять,добавлять и удалять елементы. 
ba = bytearray([72, 101, 108, 108, 111])
print(ba)----->будет Hello
и тут уже можно изменять 
ba[0] = 65  ------> буква А
print(ba) ---->bytearray(b'Aello')
Но если например нам нужно превратить в байты строку,то тут нужна кодировка. Это правило,которое говорит по себе,что и как именно преобразовать,какой символ в последовательность байтов.
text = "Привет, мир!"
byte_data = text.encode('utf-8') ---> здесь переводим в байты но в будут показаны в байтовом представлении,которое python печатает в hex для непечатаемых символов и при чем если есть запятые,точки,пробелы и остальные символы,они будут отображаться без изменений.потому что для них в utf-8 байт совпадает с ASCII.

new_text = byte_data.decode('utf-8')--->
И теперь мы обратно декодируем utf-8 в строку.
print(new_text) 
и если попытаться закодировать с неверной кодировкой ,то будет либо ошибка либо что-то совсем невразумительное.
байт это минимальная адресуемая единица информации в числе от 0 до 2, то есть Bytes и bytearray это последовательности таких чисел и интерпретируются как сырые байты а не как символы текста. они оба схожие конструкторы,просто Bytes дает неизменяемый обьект а bytearray изменяемый,но каждый свой отдельный тип способа осуществления раскрывает свою суть типа:
если создать обьект заданной длинны и заполнить его нулевыми байтами как bytes(5),то он создаст последовательность b'\x00\x00\x00\x00\x00' и здесь \x00 будет шестнадцатеричным представлением нуля.Потом способ создания из итерируемого обьекта  целых чисел в диапазоне 0---2: bytes([65,66,67])--будет b'ABC', а если выйти за пределы то вызывается ошибка ValueError,которая подчеркивает саму привязанность к 8-ми битному представлению. и еще способ через создание обьекта который реализует протокол буфера (buffer protocol) из  другого обьекта bytes или bytearray и это будет работать через копирование памяти из одного обьекта в память другого исключая дополнительные обработки или трансформации данных. также четвертый способ,через копирование с указанием самой кодировки:bytes('blabla', encoding='utf-8')-это будет преобразовывать unicode строку в последовательность байтов исходя из заданной кодировки. то есть тут мы явно говорим,что нужно преобразовать эту строку в байты для будущей записи в файл или отправки по сети и тд. bytearray() он поддерживает все те же варианты конструктора но результат поводить через само присваивание  по индексу:
arr = bytearray(b'ABC');
arr[0] = 88
и выведет b'XBC'
и здесь мы модифицируем  все данные на месте без создания новых обьектов.

Литералы байтов и их ограничения (b'...')
существует специальный префикс b за которым следуют кавычки и внутри стоят литералы допустимые ascii-символам
почему только ASCII? потому что литерал байтов,например запись b'ABC' в программе-это сразу указывает последовательность тех выбранных литералов которые мы внесли в кавычки и сказали что именно это мы хотим записать в байты в коде программы. ASCII - это стабильная 7-ми битная таблица:
7 бит это 2 в 7 степени = 128 комбинаций(от 0 до 127)-это все латинские буквы цифры,знаки препинания и управляющие символы (LF-перевод строки,CR-возврат каретки, DEL - удаление). 128 символов было достаточно для английского языка и управления телетайпами.
это английский язык и написав кириллицей без указания кодировки,будет просто ошибка,потому что с тех пор таблицы ascii расширялись и стали использовать 8 бит-256 значений

ь










если мы работаем с элементом по индексу,получим
целое число от 0 до 255.
а если делается срез,например есть строка data=b'Hello world', и мы выбираем print(data[0:5]),то выведет Hello.и для bytearray доступны все методы что в списках.
bytes и bytearray- это последовательность целых чисел которые интерпретируются как сырые байты и только.


TODO: тут закончила

       
    
     

Все данные предаваемые по сети через библиотеки socket,requests,aiohttp- это будут потоки байтов.мы отправляем байты и получаем их в ответ. и json ответ получаем от сервера приходит в виде байтов,которые потом декодируются в строку и потом нужно распарсить.
socket например это низкоуровневая библиотека и она не знает что это за байты которые мы передаем,она если видит байт со значением 72-то для нее это просто 72 и если я использую  что-то высокоуровневое,например request запрос на сайт,то эта библиотека формирует http запрос,который является текстовой командой,кодирует его в байты,отправляет по сокету и получает в ответ поток байтов. и тут она должна понять где в этом потоке заканчиваются заголовки ответа и начинается само тело.она смотрит на байты,находит последовательности,например \r\n\r\n--это для переноса строки,маркер конца заголовка http,и разделяет поток,смотрит на заголовок,к примеру(Content-Type: application/json; charset=utf-8),тут можно увидеть,что тело ответа json  и плюс он закодирован в utf-8,значит нужно декодировать в строку с decode(utf-8) и результат(строка) передать парсеру json,который превратит её обратно в высокоуровневые python -объекты,все от начала и до самого response.json() 




криптография
Порядок байтов в криптографии очень важен(endianness).если мы работаем с числами занимающими более одного байта,например целые 32-битные числа,то они могут быть представлены в памяти и в потоке данных в разном порядке,от младшего к старшему(little-endian,как в x86,то есть наименее значимый байт числа идет первым и такой порядок использует архитектура процессов x86-64,то есть все современные процессоры в персональных пк и серверах) или от старшего к младшему(big-endian,сетевой порядок,то есь тут самый значимый байт числа идет первым в последовательности и такой порядок считается естественным дял чтения для самого человека,то есть сначала сотни,потом десятки,потом единицы,и так он был принят как сетевой порядок network byte order(исторически) в стандарте интернета,как в заголовках  TCP\IP). Потому что когда мы получаем откуда-то поток байтов,в котором закодированы числа,я должна знать в каком порядке они идут(байты). и если я прочитаю первые 2 байта([52, 18]) и интерпретирую их как 16-битное число в формате процессора little-endian,то я получу совсем не то значение что задумывалось,если отправитель использовал big-endian.

и модуль struct используется здесь как раз для упаковки и распаковки таких структур составных в объекты bytes и обратно, мы задаем формат строки и struck.pack превращает число в последовательность из 4х байтов,уложенных в правильном порядке для сети или файлового формата.struck.unpack --извлекает число из 4х байтов.
вообще работа с bytes и bytearray часто сопровождается использованием struct,для интерпретации участков памяти как чисел со своей разрядностью и форматом.
при работе с большими объемами данных(аудио,видео и тд...) использование bytearray и операций с памятью через memoryview.memoryview дает представление о данных внутри bytes  или bytearray без копий. тут происходит обращение к  срезу огромных массивов байтов, интерпретация через struct без расходов на копирование данных. memoryview будет служить инструментом для взаимодействия с бинарными данными без копий,а это важно для высокопроизводительности и для подобных приложений.
Для сериализации бинарных протоколов,кроме struct,для сложных форматов есть библиотеки protobuf,msgpack,flatbuffers.Они превращают словари,списки в плотную сжатую пачку байтов,двоичный формат и это не то что можно прочесть своими глазами, и итог для ихней работы будет  объект bytes, готовая пачка байтов для отправки или сохранения.

Если взять хеш-функцию SHA-256, эта функция про битовые последовательности и если мы вычисляем хеш пароля,то мы передаем функции hashlib.sha256 объект bytes.Строку "мой_пароль" - нужно превратить в байты(b'мой_пароль') и это будет вызывать encode с дефолтной кодировкой и эти байты функция переламывает через математические сдвиги,превращая в последовательность байтов фиксированной длинны,в хеш. и этот хеш тоже байтовый(bytes).Здесь битовая точность очень важна,изменение одного бита в исходном сообщении,например смена регистра,он полностью до неузнаваемости меняет выходной хеш. и поэтому нужно оперировать байтами.
        
            
Производительность в bytearray.    
При написании TCP-прокси,который принимает поток байтов,чтото в нем поменять и переслать дальше и тут использовать неизменяемый bytes нельзя ,изза сохранения памяти и скорости,потому что при модификации нужно будет создавать новый обьект скопировав все данные,а bytearray позволит работать с одним и тем же куском памяти,как с глиной,и с методами find(),replace() и append() работают прямо на месте.и возвращаясь к написанию парсера  для HTTP- потока,данные проходят не целым куском а обрывками,своими "разорванными" пакетами,и при использовании неизменяемого bytes,с каждым новым пакетом я должна взять весь накопленный буфер,сделать его копию и к этой копии добавить новые байты а старый выбрасывается.и если пакетов тысячи,то буфер будет расти  и постоянно будет нужно выделять новую память а это пожирает процессорное времяи больше нагрузки на сборщик мусора. и bytearray будет решать это собой,следующим образом: он выделяет блок памяти с запасом,и при поступлении нового пакета,метод .append() и .extend() размещают новые байты внутри
того же блока памяти и никакого копирования старого не нужно и только если память будет заканчиваться,bytearray выделит новый блок и перенесет данные туда но будет делать это редко и по умному,чтобы минимизировать подобное в будущем,по типу работы с list,но с хранением не произвольных обьектов а плотно упакованным числам от 0 до 255. сам .append(x) - он точечный инструмент и при анализе потока и если мне нужно вставить байт или исправить один ошибочный, то вместо того чтобы разбивать весь массив на части и склеивать заново(как со строками или bytes),я указываю buffer.append(0xFF) в нужной позиции. один байт добавляется в хвост,внутренности сдвигаются и все происходит внутри существующего блока.
.extend(iterable)----- для наращивания буфера пакетами из сети.вместо  buffer=buffer+chunk-это создает новый обьект, мне нужно buffer.extend(chunk) и новые байты встраиваются прямо в существующий Buffer. и такое сердце парсера юудет собирать сообщения по кусочкам,сканировать обьект на наличие маркера конца заголовков \r\n\r\n/
.pop([i]) ------для откусывания обратной части. если мы нашли \r\n\r\n в позиции end_of_headers он обрабатывает заголовки в байтах от 0 до end_of_headers. и удаляет эти данные из буфера чтобы он не рос с бесконечностью. с bytes мне бы пришлось создавать новый срез : buffer=buffer[end_of_headers], а это уже копия всего оставшихся данных,с bytearray,если заголовки уже отработаны, а тело пришло еще не полностью,то удаление можно отложить,но когда нужно будет уже буфер очищать, .pop() позволяет удалять с любого конца,поддерживать буфер в чистоте и контролировать размер.
и само сочетание в возможности наращивать и что можно вставлять и удалять и модифицировать внутри одного участка памяти - делает bytearray для разных наших задач где нужна  скорость и экономия ресурсов,TCP\UDP-прокси которые модифицируют и пересылают потоки,парсеры протоколов не только HTTP,декодеры аудио и видео(работают с кусками данных),сама сборка бинарных данных перед записью,в смысле формирование бинарного пакета для записи.           

Любая передача выходит в байты. если с HTTP, requests библиотека является высокоуровневой абстракцией,она полностью скрывает процесс создания http текстового протокола и внутри requests формируются строки как GET/HTTP/1.1 и добавляет необходимые  заголовки как HOST и USER-Agent и все это обьединяет в одну строку с разделяющиим последовательностями \r\n. Но для самой отправки это нужно преобразовать в байты с .encode('utf-8'). сервер принимая её,делает обратное преобразование декодируя байты для HTTP парсера. и сам ответ это тоже поток байтов который requests будет получать обратно.То есть первой задачей для requests будет,то чтобы проанализировать байты,отделить метаданные от  самого тела и ответа,ищем последовательность -->  \r\n\r\n. то есь это свои байты конкретные байты  0x0D 0x0A 0x0D 0x0A (в кодировке ASCII ну и следовательно, UTF-8).библиотека понимает,что все что было до этого маркера - это заголовок,а все что после- это тело ответа,потом она считает байты заголовков,декодирует в строку и парсит как текст.

Content-Type: application/json; charset=utf-8  
Например здесь мы указываем,что тело ответа нужно интерпретировать как json, и то что оно закодировани в utf-8. потом она берет оставшееся тело  и применяет к нему  .decode('utf-8'). Полученное передается в json.laods(), который преобразует в словари,списки,строки. то есть мы идем из быйты из сокета ---> анализ сырых байтов для разделения ---> декодирование первой части бацтов в строки для заголовков ----> декодирование второй части байтов в строку для заголовков ----> парсинг строки в обьект. И когда requests или другой какой-нибудь парсер,работает с буфером bytearray,то ошибка всплывает изза того,что буфер может содержать неполное сообщение,то есть там может лежать само начало заголовка,например:b'GET / HTTP/1.1\r\nHost: exa'  но его конец еще не пришел и алгоритм самого парсера обязан учитывать такое. он будет постоянно сканировать  буфер bytearray в поисках \r\n\r\n, но не найдет,он будет считать что заголовок еще не собран и будет ждать новых данных которые будут в append,в тот же буфер. это будет эффективно,потому что будут создаватся новые обьекты на пришедший пакет и изменяемость bytearray будет позволять реализовать stateful-процесс накопления и анализа в одном месте памяти и когда заголовок будет распарсен,при заголовке например:charset=windows-1251, библиотека должна запомнить это не просто как строку а как инструкцию для вызова .drcode(). Но ,если тело будет не json, а картинка какая-то бинарная,то заголовок:Content-Type: image/jpeg будет уже говорить что декодировать байты в строку уже не нужно и библиотека она оставит тело ответа в виде bytes и отдаст мне его как есть. если Content-Type текстовый- то (json,html,xml)- байты декодируются в строку с указанной кодировкой,если бинарный- то оставляет как bytes.



           
Различие между str bytes- в python 2 смешение строк и байтов было источником багов особенно при работе с ASCII текстом.и те ошибки которые я ранее упоминала,это было одним из этого. то есть это было следствием того,что программа неявно переводила байты в строки(гдето в глубине) или наоборот,предполагая кодировку по умолчанию.в Python3 провели границу,str- это будет текст(unicode),а bytes- это будут данные. и текста без кодировки не существует и данные без кодировки не текст. и encode/decode- в своем роде шлюзы между этими двумя мирами.

       

отличие bytearray от bytes в том что bytearray изменяемый тип данных а  bytes нет
bytearray это последовательность интов.
в python2 то что ранее было строкой а теперь в python3 называется bytes. и ранее строки были битовые а теперь юникодные
потому что в python2 был отдельный тип unicode, а в python3 уже называется str. И unicode object - это все еще строка

ord('=')чтобы узнать какое по порядку символ =

(61).to_bytes()
int.from_bytes(b'\x3d') hex символ 61
oct(61)  восьмеричная запись

b'=' == b'\x3d' == b'\075' ---> True

b'='.decode('ascii')  --->True
b'\x3d'.decode('ascii')  --->True
b'\075'.decode('ascii')  --->True

Значение 127- это последнее значение которое можно записать внутри байт как обычный символ и последующие значение уже будут как hex.

bytes-это для хранения  передачи и для данных,а Bytearray- это для модификации,сборки и обработки
Сама функция ord- она не работает  с байтами напрямую,а только с кодовыми точками,напрмиер ord('A') 
и ord('A')- вернет номер 65.  TODO: вот тут подумать еще



